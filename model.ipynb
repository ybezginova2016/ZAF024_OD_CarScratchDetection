{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ZAF024_OD_CarScratchDetection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "Car scratch detection using computer vision is a project that aims to automatically identify and localize scratches on car surfaces using image processing techniques. This project has significant applications in the automotive industry, where car manufacturers and car owners require a reliable and efficient method for detecting and repairing scratches. By automating the process of scratch detection, this project has the potential to save time and reduce costs for car manufacturers and owners while improving the quality of car repair services."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Methodology\n",
        "This use case follows the methodology mentioned below:\n",
        "- Data Preparation:\n",
        "The first step is to collect and prepare the car scratch detection dataset. The dataset should include images of car surfaces with and without scratches, and annotations that indicate the location of the scratches. The annotations could be in the form of bounding boxes, masks, or keypoints. The dataset should be split into training, validation, and test sets.\n",
        "\n",
        "- Model Selection:\n",
        "The next step is to select the YOLOv5 model architecture for fine-tuning. You can choose from various pre-trained models available on the official YOLOv5 GitHub repository.\n",
        "\n",
        "- Preprocessing:\n",
        "Before training the YOLOv5 model, you need to preprocess the car scratch detection data. This could involve resizing the images, normalizing the pixel values, and augmenting the data to increase its variability. Common data augmentation techniques for object detection include random cropping, flipping, rotation, and color jittering.\n",
        "\n",
        "- Fine-tuning:\n",
        "The YOLOv5 model can be fine-tuned on the car scratch detection dataset using transfer learning. Transfer learning involves using a pre-trained model as a starting point and fine-tuning it on a new dataset. In this case, you will fine-tune the pre-trained YOLOv5 model on the car scratch detection dataset to learn the specific features and patterns of car scratches.\n",
        "\n",
        "- Training:\n",
        "The fine-tuned YOLOv5 model can be trained using the training set and validated using the validation set. During training, the model learns to predict the location and size of scratches in the input images. You can monitor the training progress using metrics such as mean average precision (mAP) and loss.\n",
        "\n",
        "- Evaluation:\n",
        "Once the YOLOv5 model is trained, you can evaluate its performance on the test set. This involves measuring its accuracy, precision, recall, and F1-score on the test images. You can also visualize the predicted bounding boxes on the test images to see how well the model is detecting scratches.\n",
        "\n",
        "- Deployment:\n",
        "The final step is to deploy the YOLOv5 model for car scratch detection. This could involve integrating it into a mobile or web application, or using it as a backend for an automated car repair system. You can also fine-tune the model on new car scratch detection data to improve its performance over time."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business Segments\n",
        "- Automotive Industry"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\n",
        "- Car Scratch Detection Data - [Link](https://www.kaggle.com/datasets/aniketmalviya/car-scratch-detection)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Papers\n",
        "- YOLOv5 - [Link](https://zenodo.org/record/7347926#.ZBzP8XZBy3A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfWlANOTJh8y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlSxjRenGlzH",
        "outputId": "90c11b80-bc90-4501-de2c-8b15a11cd415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Car Scratch Detection/yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Car Scratch Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTKbnIGbLqu3",
        "outputId": "2af83480-22c7-48ab-d43f-7360cfa7e722"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 ðŸš€ 2023-3-23 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 25.7/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw-zKLE8FYHz",
        "outputId": "51d66a10-a7f3-45f4-b588-b30c5524bacc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "fatal: cannot change to '/content/drive/MyDrive/Colab': No such file or directory\n",
            "YOLOv5 ðŸš€ 2023-3-23 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-23 21:01:27.151225: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-23 21:01:28.041189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-23 21:01:28.041313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-23 21:01:28.041335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/Car Scratch Detection/datasets/coco128/labels/train.cache... 880 images, 6 backgrounds, 0 corrupt: 100% 886/886 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/Car Scratch Detection/datasets/coco128/labels/test.cache... 145 images, 0 backgrounds, 0 corrupt: 100% 145/145 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.32 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/49     0.971G     0.1075      0.026          0         30        320: 100% 56/56 [00:28<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.07it/s]\n",
            "                   all        145        235    0.00773      0.515     0.0101    0.00243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/49       1.2G    0.08914    0.03219          0         17        320: 100% 56/56 [00:23<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.30it/s]\n",
            "                   all        145        235     0.0777      0.136     0.0341    0.00777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/49       1.2G    0.08045    0.03104          0         25        320: 100% 56/56 [00:22<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.83it/s]\n",
            "                   all        145        235      0.156      0.183     0.0888     0.0203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/49       1.2G    0.07565    0.03104          0         20        320: 100% 56/56 [00:24<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.16it/s]\n",
            "                   all        145        235      0.178      0.277      0.139     0.0385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/49       1.2G    0.06733    0.03043          0         22        320: 100% 56/56 [00:25<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.91it/s]\n",
            "                   all        145        235      0.332      0.387      0.276     0.0777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/49       1.2G    0.06555    0.02922          0         22        320: 100% 56/56 [00:25<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.28it/s]\n",
            "                   all        145        235      0.456       0.37      0.318        0.1\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/49       1.2G    0.06353    0.02956          0         17        320: 100% 56/56 [00:22<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.15it/s]\n",
            "                   all        145        235      0.521      0.396      0.387      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/49       1.2G    0.06125       0.03          0         27        320: 100% 56/56 [00:23<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.09it/s]\n",
            "                   all        145        235      0.428      0.357      0.319     0.0986\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/49       1.2G     0.0599    0.02902          0         17        320: 100% 56/56 [00:25<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.00it/s]\n",
            "                   all        145        235      0.462      0.362      0.328      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/49       1.2G    0.05922    0.02862          0         18        320: 100% 56/56 [00:26<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.83it/s]\n",
            "                   all        145        235      0.403      0.421      0.342       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/49       1.2G    0.05765    0.02792          0         23        320: 100% 56/56 [00:25<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.63it/s]\n",
            "                   all        145        235      0.627      0.443      0.478      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/49       1.2G    0.05704    0.02842          0         25        320: 100% 56/56 [00:23<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.17it/s]\n",
            "                   all        145        235      0.601      0.438      0.475      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/49       1.2G    0.05534    0.02784          0         18        320: 100% 56/56 [00:23<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.41it/s]\n",
            "                   all        145        235        0.5        0.4      0.388      0.117\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/49       1.2G    0.05625     0.0279          0         15        320: 100% 56/56 [00:25<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.12it/s]\n",
            "                   all        145        235      0.547      0.457      0.433      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/49       1.2G    0.05408    0.02672          0         25        320: 100% 56/56 [00:25<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.27it/s]\n",
            "                   all        145        235      0.548      0.505      0.451      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/49       1.2G    0.05367    0.02779          0         16        320: 100% 56/56 [00:24<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.42it/s]\n",
            "                   all        145        235      0.572      0.536      0.484      0.171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/49       1.2G    0.05312    0.02717          0         27        320: 100% 56/56 [00:23<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.57it/s]\n",
            "                   all        145        235      0.585      0.536      0.489      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/49       1.2G    0.05235    0.02598          0         20        320: 100% 56/56 [00:24<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.26it/s]\n",
            "                   all        145        235      0.605      0.464      0.474      0.171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/49       1.2G      0.052    0.02653          0         18        320: 100% 56/56 [00:25<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.25it/s]\n",
            "                   all        145        235      0.601      0.515      0.484      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/49       1.2G    0.05099    0.02659          0         18        320: 100% 56/56 [00:25<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.30it/s]\n",
            "                   all        145        235      0.592      0.525      0.494      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/49       1.2G    0.05079     0.0265          0         25        320: 100% 56/56 [00:23<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.34it/s]\n",
            "                   all        145        235      0.553      0.396      0.391      0.132\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/49       1.2G    0.05022    0.02643          0         24        320: 100% 56/56 [00:23<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.25it/s]\n",
            "                   all        145        235      0.607      0.486      0.473      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/49       1.2G    0.04991    0.02585          0         27        320: 100% 56/56 [00:24<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.19it/s]\n",
            "                   all        145        235        0.6      0.587      0.515      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/49       1.2G    0.04878    0.02581          0         29        320: 100% 56/56 [00:26<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.15it/s]\n",
            "                   all        145        235      0.577      0.536      0.474      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/49       1.2G    0.04874    0.02562          0         22        320: 100% 56/56 [00:24<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.59it/s]\n",
            "                   all        145        235      0.661      0.498      0.483      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/49       1.2G    0.04812    0.02471          0         14        320: 100% 56/56 [00:23<00:00,  2.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.25it/s]\n",
            "                   all        145        235      0.616      0.532      0.488      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/49       1.2G    0.04804    0.02528          0         23        320: 100% 56/56 [00:23<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.06it/s]\n",
            "                   all        145        235      0.577      0.519      0.472      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/49       1.2G    0.04636    0.02452          0         25        320: 100% 56/56 [00:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.01it/s]\n",
            "                   all        145        235      0.553      0.519      0.487      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/49       1.2G    0.04627    0.02467          0         24        320: 100% 56/56 [00:25<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.07it/s]\n",
            "                   all        145        235      0.518      0.498      0.455      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/49       1.2G    0.04573    0.02427          0         19        320: 100% 56/56 [00:24<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.42it/s]\n",
            "                   all        145        235      0.548      0.553      0.477      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/49       1.2G    0.04575      0.024          0         24        320: 100% 56/56 [00:23<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.02it/s]\n",
            "                   all        145        235      0.585      0.523      0.476      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/49       1.2G    0.04487    0.02442          0         22        320: 100% 56/56 [00:24<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.10it/s]\n",
            "                   all        145        235      0.587      0.579      0.504      0.206\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/49       1.2G    0.04417    0.02422          0         31        320: 100% 56/56 [00:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.00it/s]\n",
            "                   all        145        235      0.576      0.523      0.473      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/49       1.2G    0.04428    0.02339          0         26        320: 100% 56/56 [00:24<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.53it/s]\n",
            "                   all        145        235      0.605      0.562      0.502      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/49       1.2G     0.0436    0.02346          0         19        320: 100% 56/56 [00:23<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.44it/s]\n",
            "                   all        145        235      0.618      0.566      0.504      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/49       1.2G    0.04305     0.0239          0         15        320: 100% 56/56 [00:24<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.23it/s]\n",
            "                   all        145        235      0.629      0.548      0.479       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/49       1.2G    0.04246    0.02278          0         23        320: 100% 56/56 [00:25<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.16it/s]\n",
            "                   all        145        235      0.604      0.532      0.475        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/49       1.2G    0.04236    0.02254          0         20        320: 100% 56/56 [00:25<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.99it/s]\n",
            "                   all        145        235      0.623      0.545      0.503      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/49       1.2G    0.04114    0.02305          0         23        320: 100% 56/56 [00:23<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.19it/s]\n",
            "                   all        145        235      0.559      0.557      0.499      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/49       1.2G    0.04139     0.0227          0         24        320: 100% 56/56 [00:23<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.97it/s]\n",
            "                   all        145        235       0.57      0.562      0.501      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/49       1.2G    0.04072    0.02191          0         13        320: 100% 56/56 [00:24<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.08it/s]\n",
            "                   all        145        235      0.588      0.557      0.513      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/49       1.2G    0.04081    0.02229          0         31        320: 100% 56/56 [00:25<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.91it/s]\n",
            "                   all        145        235      0.615      0.574      0.517      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/49       1.2G    0.04055     0.0217          0         21        320: 100% 56/56 [00:23<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.24it/s]\n",
            "                   all        145        235      0.602      0.566      0.513      0.195\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/49       1.2G     0.0402    0.02156          0         17        320: 100% 56/56 [00:24<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.20it/s]\n",
            "                   all        145        235      0.582       0.58      0.494      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/49       1.2G    0.03999    0.02269          0         17        320: 100% 56/56 [00:26<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.23it/s]\n",
            "                   all        145        235        0.6       0.58      0.485      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/49       1.2G    0.03947    0.02178          0         21        320: 100% 56/56 [00:26<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.96it/s]\n",
            "                   all        145        235      0.614      0.587      0.501      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/49       1.2G    0.03863    0.02125          0         16        320: 100% 56/56 [00:25<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.92it/s]\n",
            "                   all        145        235      0.606      0.579      0.509      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/49       1.2G    0.03853    0.02085          0         21        320: 100% 56/56 [00:23<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.25it/s]\n",
            "                   all        145        235      0.601      0.596      0.498      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/49       1.2G    0.03797    0.02141          0         19        320: 100% 56/56 [00:23<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.31it/s]\n",
            "                   all        145        235      0.598      0.596      0.498      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/49       1.2G    0.03798    0.02067          0         17        320: 100% 56/56 [00:25<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.11it/s]\n",
            "                   all        145        235      0.587      0.587      0.496      0.196\n",
            "\n",
            "50 epochs completed in 0.395 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:05<00:00,  1.04s/it]\n",
            "                   all        145        235      0.585      0.579      0.505      0.207\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train.py --img 320 --batch 16 --epochs 50 --data coco128.yaml --weights yolov5s.pt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
